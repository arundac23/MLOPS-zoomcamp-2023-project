{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import mlflow\n",
    "import pickle\n",
    "from hyperopt import hp, STATUS_OK, Trials, pyll,fmin,tpe\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket Name: mlflow-artifact-remote-chicago-taxi-prediction\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# List all buckets in your S3 account\n",
    "response = s3.list_buckets()\n",
    "buckets = response['Buckets']\n",
    "\n",
    "for bucket in buckets:\n",
    "    print(f\"Bucket Name: {bucket['Name']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://mlflow-artifact-remote-chicago-taxi-prediction/1/a6203da436864c7ea7d2ce768f2ec697/artifacts/models\n"
     ]
    }
   ],
   "source": [
    "RUN_ID = 'a6203da436864c7ea7d2ce768f2ec697'\n",
    "logged_model = f's3://mlflow-artifact-remote-chicago-taxi-prediction/1/{RUN_ID}/artifacts/models'\n",
    "print(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1014783894.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    mlflow artifacts download \\\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "mlflow artifacts download \\\n",
    "    --run-id ${MODEL_RUN_ID} \\\n",
    "    --artifact-path model \\\n",
    "    --dst-path ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACKING_SERVER_HOST = 'ec2-3-145-52-96.us-east-2.compute.amazonaws.com'\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking uri \"http://ec2-3-145-52-96.us-east-2.compute.amazonaws.com:5000\"\n"
     ]
    }
   ],
   "source": [
    "print(f'tracking uri \"{mlflow.get_tracking_uri()}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://mlflow-artifact-remote-chicago-taxi-prediction/1', creation_time=1691888942267, experiment_id='1', last_update_time=1691888942267, lifecycle_stage='active', name='chicago-taxi-experiment', tags={}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow_experiment_name = \"chicago-taxi-experiment\"\n",
    "\n",
    "mlflow.set_experiment(mlflow_experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN DATASET:\n",
    "Train_parquet_file_path = 'data/chicago_taxi_train_dataset_2023-01.parquet'  # Replace with the desired Parquet file path\n",
    "# VALIDATION DATASET:\n",
    "Val_parquet_file_path = 'data/chicago_taxi_Val_dataset_2023-02.parquet'\n",
    "# TEST DATASET:\n",
    "Test_parquet_file_path = 'data/chicago_taxi_test_dataset_2023-03.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_r = pd.read_parquet(Train_parquet_file_path)\n",
    "df_val_r = pd.read_parquet(Val_parquet_file_path)\n",
    "df_test_r = pd.read_parquet(Test_parquet_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>trip_start_timestamp</th>\n",
       "      <th>trip_end_timestamp</th>\n",
       "      <th>trip_seconds</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>pickup_census_tract</th>\n",
       "      <th>dropoff_census_tract</th>\n",
       "      <th>pickup_community_area</th>\n",
       "      <th>dropoff_community_area</th>\n",
       "      <th>...</th>\n",
       "      <th>extras</th>\n",
       "      <th>trip_total</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>company</th>\n",
       "      <th>pickup_centroid_latitude</th>\n",
       "      <th>pickup_centroid_longitude</th>\n",
       "      <th>pickup_centroid_location</th>\n",
       "      <th>dropoff_centroid_latitude</th>\n",
       "      <th>dropoff_centroid_longitude</th>\n",
       "      <th>dropoff_centroid__location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0fca59218b11688279d795c03c4d16f851f13fa0</td>\n",
       "      <td>e2c349c7cbb608d552aa0b5814031943f13641ef9e50d8...</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-01-01 00:15:00</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>4.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.50</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Taxicab Insurance Agency Llc</td>\n",
       "      <td>41.944227</td>\n",
       "      <td>-87.655998</td>\n",
       "      <td>POINT (-87.6559981815 41.9442266014)</td>\n",
       "      <td>41.878866</td>\n",
       "      <td>-87.625192</td>\n",
       "      <td>POINT (-87.6251921424 41.8788655841)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1e539d6e7501164c6b76b761c3152c235e206d59</td>\n",
       "      <td>4ab7a7510c1ebcc9b2e3eaa7bdd6508dbea34da7986aca...</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-01-01 00:15:00</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>16.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>53.00</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Sun Taxi</td>\n",
       "      <td>41.980264</td>\n",
       "      <td>-87.913625</td>\n",
       "      <td>POINT (-87.913624596 41.9802643146)</td>\n",
       "      <td>41.899602</td>\n",
       "      <td>-87.633308</td>\n",
       "      <td>POINT (-87.6333080367 41.899602111)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2b3c5200439d51f626b60380809bbbcca766a85b</td>\n",
       "      <td>8c76eb82f069c0731a0049cb78898f02cc5ac6990244c9...</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-01-01 00:15:00</td>\n",
       "      <td>844.0</td>\n",
       "      <td>3.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.17</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Sun Taxi</td>\n",
       "      <td>41.901207</td>\n",
       "      <td>-87.676356</td>\n",
       "      <td>POINT (-87.6763559892 41.9012069941)</td>\n",
       "      <td>41.899602</td>\n",
       "      <td>-87.633308</td>\n",
       "      <td>POINT (-87.6333080367 41.899602111)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45b2ea39cfff64d61a46ef016e16f8ee74e9ed23</td>\n",
       "      <td>a688de71e9eb70603ba839dc7faf949968ae3e971e0575...</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>361.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.50</td>\n",
       "      <td>Cash</td>\n",
       "      <td>5 Star Taxi</td>\n",
       "      <td>41.878866</td>\n",
       "      <td>-87.625192</td>\n",
       "      <td>POINT (-87.6251921424 41.8788655841)</td>\n",
       "      <td>41.878866</td>\n",
       "      <td>-87.625192</td>\n",
       "      <td>POINT (-87.6251921424 41.8788655841)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>464df6aaaf97ca8745985c2a5b2e481067a2bfb6</td>\n",
       "      <td>8b1a88e5a09cfd55ca72d267f00f56fa50a42aa322bdfe...</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-01-01 00:15:00</td>\n",
       "      <td>704.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Flash Cab</td>\n",
       "      <td>41.968069</td>\n",
       "      <td>-87.721559</td>\n",
       "      <td>POINT (-87.7215590627 41.968069)</td>\n",
       "      <td>41.968069</td>\n",
       "      <td>-87.721559</td>\n",
       "      <td>POINT (-87.7215590627 41.968069)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    trip_id  \\\n",
       "0  0fca59218b11688279d795c03c4d16f851f13fa0   \n",
       "1  1e539d6e7501164c6b76b761c3152c235e206d59   \n",
       "2  2b3c5200439d51f626b60380809bbbcca766a85b   \n",
       "3  45b2ea39cfff64d61a46ef016e16f8ee74e9ed23   \n",
       "4  464df6aaaf97ca8745985c2a5b2e481067a2bfb6   \n",
       "\n",
       "                                             taxi_id trip_start_timestamp  \\\n",
       "0  e2c349c7cbb608d552aa0b5814031943f13641ef9e50d8...           2023-01-01   \n",
       "1  4ab7a7510c1ebcc9b2e3eaa7bdd6508dbea34da7986aca...           2023-01-01   \n",
       "2  8c76eb82f069c0731a0049cb78898f02cc5ac6990244c9...           2023-01-01   \n",
       "3  a688de71e9eb70603ba839dc7faf949968ae3e971e0575...           2023-01-01   \n",
       "4  8b1a88e5a09cfd55ca72d267f00f56fa50a42aa322bdfe...           2023-01-01   \n",
       "\n",
       "   trip_end_timestamp  trip_seconds  trip_miles  pickup_census_tract  \\\n",
       "0 2023-01-01 00:15:00        1037.0        4.82                  NaN   \n",
       "1 2023-01-01 00:15:00        1341.0       16.63                  NaN   \n",
       "2 2023-01-01 00:15:00         844.0        3.84                  NaN   \n",
       "3 2023-01-01 00:00:00         361.0        0.63                  NaN   \n",
       "4 2023-01-01 00:15:00         704.0        0.99                  NaN   \n",
       "\n",
       "   dropoff_census_tract pickup_community_area dropoff_community_area  ...  \\\n",
       "0                   NaN                   6.0                   32.0  ...   \n",
       "1                   NaN                  76.0                    8.0  ...   \n",
       "2                   NaN                  24.0                    8.0  ...   \n",
       "3                   NaN                  32.0                   32.0  ...   \n",
       "4                   NaN                  14.0                   14.0  ...   \n",
       "\n",
       "   extras  trip_total  payment_type                       company  \\\n",
       "0     0.0       19.50   Credit Card  Taxicab Insurance Agency Llc   \n",
       "1     6.0       53.00   Credit Card                      Sun Taxi   \n",
       "2     0.0       20.17        Mobile                      Sun Taxi   \n",
       "3     1.0        6.50          Cash                   5 Star Taxi   \n",
       "4     0.0        7.75          Cash                     Flash Cab   \n",
       "\n",
       "   pickup_centroid_latitude pickup_centroid_longitude  \\\n",
       "0                 41.944227                -87.655998   \n",
       "1                 41.980264                -87.913625   \n",
       "2                 41.901207                -87.676356   \n",
       "3                 41.878866                -87.625192   \n",
       "4                 41.968069                -87.721559   \n",
       "\n",
       "               pickup_centroid_location  dropoff_centroid_latitude  \\\n",
       "0  POINT (-87.6559981815 41.9442266014)                  41.878866   \n",
       "1   POINT (-87.913624596 41.9802643146)                  41.899602   \n",
       "2  POINT (-87.6763559892 41.9012069941)                  41.899602   \n",
       "3  POINT (-87.6251921424 41.8788655841)                  41.878866   \n",
       "4      POINT (-87.7215590627 41.968069)                  41.968069   \n",
       "\n",
       "   dropoff_centroid_longitude            dropoff_centroid__location  \n",
       "0                  -87.625192  POINT (-87.6251921424 41.8788655841)  \n",
       "1                  -87.633308   POINT (-87.6333080367 41.899602111)  \n",
       "2                  -87.633308   POINT (-87.6333080367 41.899602111)  \n",
       "3                  -87.625192  POINT (-87.6251921424 41.8788655841)  \n",
       "4                  -87.721559      POINT (-87.7215590627 41.968069)  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame, categorical_features: List[str], numerical_features: List[str], verbose: bool = False):\n",
    "\n",
    "    df = df[df.trip_seconds.notnull()]\n",
    "    df = df[df.trip_start_timestamp.notnull()]\n",
    "    \n",
    "    df = df[(df['trip_seconds'] > 60) & (df['trip_seconds'] < 3600)]\n",
    "\n",
    "    # Create the 'duration' column in minutes as the target variable\n",
    "    df['duration'] = df['trip_seconds'] / 60\n",
    "\n",
    "    # Preprocess categorical features\n",
    "    for column in categorical_features:\n",
    "        df[column].fillna(-1, inplace=True)\n",
    "        df[column] = df[column].astype('str')\n",
    "        df[column] = df[column].str.lower().str.replace(' ', '_')\n",
    "\n",
    "    # Select only the relevant columns\n",
    "    target = ['duration']\n",
    "    selected_columns = categorical_features + numerical_features + target\n",
    "    df = df[selected_columns]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nshape of the data: {df.shape}\")\n",
    "        print(f\"\\ndata types:\\n{df.dtypes}\")\n",
    "        print(f\"\\ncategorical_features: {categorical_features}\")\n",
    "        print(f\"\\nnumerical_features: {numerical_features}\")\n",
    "        print(f\"\\ntarget variable: {target}\")\n",
    "\n",
    "    return df[categorical_features + numerical_features], df[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "shape of the data: (542815, 4)\n",
      "\n",
      "data types:\n",
      "pickup_community_area      object\n",
      "dropoff_community_area     object\n",
      "trip_miles                float64\n",
      "duration                  float64\n",
      "dtype: object\n",
      "\n",
      "categorical_features: ['pickup_community_area', 'dropoff_community_area']\n",
      "\n",
      "numerical_features: ['trip_miles']\n",
      "\n",
      "target variable: ['duration']\n"
     ]
    }
   ],
   "source": [
    "df_test, y_test = preprocess_data(\n",
    "    df_test_r,\n",
    "    categorical_features=['pickup_community_area','dropoff_community_area'],\n",
    "    numerical_features=['trip_miles'],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "shape of the data: (417382, 4)\n",
      "\n",
      "data types:\n",
      "pickup_community_area      object\n",
      "dropoff_community_area     object\n",
      "trip_miles                float64\n",
      "duration                  float64\n",
      "dtype: object\n",
      "\n",
      "categorical_features: ['pickup_community_area', 'dropoff_community_area']\n",
      "\n",
      "numerical_features: ['trip_miles']\n",
      "\n",
      "target variable: ['duration']\n"
     ]
    }
   ],
   "source": [
    "df_val, y_val = preprocess_data(\n",
    "    df_val_r,\n",
    "    categorical_features=['pickup_community_area','dropoff_community_area'],\n",
    "    numerical_features=['trip_miles'],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "shape of the data: (387579, 4)\n",
      "\n",
      "data types:\n",
      "pickup_community_area      object\n",
      "dropoff_community_area     object\n",
      "trip_miles                float64\n",
      "duration                  float64\n",
      "dtype: object\n",
      "\n",
      "categorical_features: ['pickup_community_area', 'dropoff_community_area']\n",
      "\n",
      "numerical_features: ['trip_miles']\n",
      "\n",
      "target variable: ['duration']\n"
     ]
    }
   ],
   "source": [
    "df_train, y_train = preprocess_data(\n",
    "    df_train_r,\n",
    "    categorical_features=['pickup_community_area','dropoff_community_area'],\n",
    "    numerical_features=['trip_miles'],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dictionaries(df:pd.DataFrame, categorical_features:List[str], numerical_features:List[str]):\n",
    "    dicts = df[categorical_features + numerical_features].to_dict(orient='records')\n",
    "    return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = prepare_dictionaries(\n",
    "    df_train,\n",
    "    categorical_features=['pickup_community_area','dropoff_community_area'],\n",
    "    numerical_features=['trip_miles']\n",
    ")\n",
    "val_dict = prepare_dictionaries(\n",
    "    df_val,\n",
    "    categorical_features=['pickup_community_area','dropoff_community_area'],\n",
    "    numerical_features=['trip_miles']\n",
    ")\n",
    "test_dict = prepare_dictionaries(\n",
    "    df_test,\n",
    "    categorical_features=['pickup_community_area','dropoff_community_area'],\n",
    "    numerical_features=['trip_miles']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values\n",
    "y_val = y_val.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dv = DictVectorizer()\n",
    "# X_train = dv.fit_transform(train_dict)\n",
    "# X_val = dv.transform(val_dict)\n",
    "# X_test = dv.transform(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arundac23/enter/envs/mlops-project-2023/lib/python3.9/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 17\u001b[0m\n\u001b[1;32m      5\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m100\u001b[39m, \n\u001b[1;32m      7\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m10\u001b[39m, \n\u001b[1;32m      8\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmin_samples_split\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m10\u001b[39m,\n\u001b[1;32m      9\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmin_samples_leaf\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m4\u001b[39m\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     12\u001b[0m pipeline \u001b[39m=\u001b[39m make_pipeline(\n\u001b[1;32m     13\u001b[0m     DictVectorizer(),\n\u001b[1;32m     14\u001b[0m     RandomForestRegressor(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m pipeline\u001b[39m.\u001b[39;49mfit(train_dict, y_train)\n\u001b[1;32m     18\u001b[0m y_pred \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mpredict(val_dict)\n\u001b[1;32m     19\u001b[0m rmse \u001b[39m=\u001b[39m mean_squared_error(y_val, y_pred, squared\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/enter/envs/mlops-project-2023/lib/python3.9/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/enter/envs/mlops-project-2023/lib/python3.9/site-packages/sklearn/pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    419\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 420\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    422\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/enter/envs/mlops-project-2023/lib/python3.9/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/enter/envs/mlops-project-2023/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    445\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    447\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    457\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    458\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    459\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    460\u001b[0m )(\n\u001b[1;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    462\u001b[0m         t,\n\u001b[1;32m    463\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    464\u001b[0m         X,\n\u001b[1;32m    465\u001b[0m         y,\n\u001b[1;32m    466\u001b[0m         sample_weight,\n\u001b[1;32m    467\u001b[0m         i,\n\u001b[1;32m    468\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    469\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    470\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    471\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    472\u001b[0m     )\n\u001b[1;32m    473\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    474\u001b[0m )\n\u001b[1;32m    476\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/enter/envs/mlops-project-2023/lib/python3.9/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/enter/envs/mlops-project-2023/lib/python3.9/site-packages/joblib/parallel.py:1855\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1854\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1855\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1857\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1858\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1859\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/enter/envs/mlops-project-2023/lib/python3.9/site-packages/joblib/parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1783\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1784\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1785\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1786\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/enter/envs/mlops-project-2023/lib/python3.9/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/enter/envs/mlops-project-2023/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 188\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/enter/envs/mlops-project-2023/lib/python3.9/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/enter/envs/mlops-project-2023/lib/python3.9/site-packages/sklearn/tree/_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1292\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \n\u001b[1;32m   1294\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1318\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1320\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m   1321\u001b[0m         X,\n\u001b[1;32m   1322\u001b[0m         y,\n\u001b[1;32m   1323\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1324\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m   1325\u001b[0m     )\n\u001b[1;32m   1326\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/enter/envs/mlops-project-2023/lib/python3.9/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "with mlflow.start_run(run_name='Random_forest'):\n",
    "    params = {\n",
    "        'n_estimators': 100, \n",
    "        'max_depth': 10, \n",
    "        'min_samples_split': 10,\n",
    "        'min_samples_leaf': 4\n",
    "    }\n",
    "\n",
    "    pipeline = make_pipeline(\n",
    "        DictVectorizer(),\n",
    "        RandomForestRegressor(random_state=42)\n",
    "    )\n",
    "\n",
    "    pipeline.fit(train_dict, y_train)\n",
    "    y_pred = pipeline.predict(val_dict)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    rmse_test = mean_squared_error(y_test, pipeline.predict(test_dict), squared=False)\n",
    "    mlflow.set_tag('developer', 'Arun Dhanapalan')\n",
    "    mlflow.set_tag('project', 'chicago-taxi-prediction')\n",
    "    mlflow.log_param('train-data_path', Train_parquet_file_path)\n",
    "    mlflow.log_param('Validation-data_path', Val_parquet_file_path)\n",
    "    mlflow.log_metric('val_rmse', rmse)\n",
    "    mlflow.log_metric('test_rmse', rmse_test)\n",
    "    mlflow.set_tag(\"model_name\", 'Random_forest')\n",
    "    mlflow.sklearn.log_model(pipeline, artifact_path=\"models\")\n",
    "    print(f'Hyperparameters: {params}')\n",
    "    print(f'Validation RMSE: {rmse}') \n",
    "    print(f'Test RMSE: {rmse_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "import mlflow\n",
    "\n",
    "ML_FLOW_TRACKING_URI = \"http://ec2-3-145-52-96.us-east-2.compute.amazonaws.com:5000\"\n",
    "client = MlflowClient(tracking_uri=ML_FLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.entities import ViewType\n",
    "runs = client.search_runs(\n",
    "    experiment_ids='1',\n",
    "    filter_string='metrics.test_rmse < 9',\n",
    "    run_view_type=ViewType.ACTIVE_ONLY\n",
    "    # max_results=5,\n",
    "    # order_by=[\"metrics.test_rmse ASC\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: a6203da436864c7ea7d2ce768f2ec697, \n",
      "Val_rmse: 8.119 \n",
      "Test rmse: 8.658\n",
      "run id: 5c5419efd6f64a9bb9f168860160a8dd, \n",
      "Val_rmse: 8.106 \n",
      "Test rmse: 8.645\n",
      "run id: 15c1ae822734476d96e118a9e7e7034a, \n",
      "Val_rmse: 8.127 \n",
      "Test rmse: 8.666\n",
      "run id: e5467e29da6f46a9ac9731515a9fa195, \n",
      "Val_rmse: 8.119 \n",
      "Test rmse: 8.658\n"
     ]
    }
   ],
   "source": [
    "for run in runs:\n",
    "    print(f\"run id: {run.info.run_id}, \\nVal_rmse: {run.data.metrics['val_rmse']:.3f} \\nTest rmse: {run.data.metrics['test_rmse']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(ML_FLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'chicago-taxi-prediction-model' already exists. Creating a new version of this model...\n",
      "2023/08/18 17:00:33 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: chicago-taxi-prediction-model, version 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs:/a6203da436864c7ea7d2ce768f2ec697/models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '4' of model 'chicago-taxi-prediction-model'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1692392433395, current_stage='None', description='', last_updated_timestamp=1692392433395, name='chicago-taxi-prediction-model', run_id='a6203da436864c7ea7d2ce768f2ec697', run_link='', source='s3://mlflow-artifact-remote-chicago-taxi-prediction/1/a6203da436864c7ea7d2ce768f2ec697/artifacts/models', status='READY', status_message='', tags={}, user_id='', version='4'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = \"a6203da436864c7ea7d2ce768f2ec697\"\n",
    "model_uri = f\"runs:/{run_id}/models\"\n",
    "print(model_uri)\n",
    "mlflow.register_model(model_uri=model_uri, name=\"chicago-taxi-prediction-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: 1, status: Staging\n",
      "version: 3, status: None\n",
      "version: 4, status: Production\n"
     ]
    }
   ],
   "source": [
    "model_name = 'chicago-taxi-prediction-model'\n",
    "latest_version = client.get_latest_versions(name=model_name)\n",
    "for version in latest_version:\n",
    "    print(f\"version: {version.version}, status: {version.current_stage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1692392433395, current_stage='Production', description='', last_updated_timestamp=1692392470411, name='chicago-taxi-prediction-model', run_id='a6203da436864c7ea7d2ce768f2ec697', run_link='', source='s3://mlflow-artifact-remote-chicago-taxi-prediction/1/a6203da436864c7ea7d2ce768f2ec697/artifacts/models', status='READY', status_message='', tags={}, user_id='', version='4'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=4,\n",
    "    stage=\"production\",\n",
    "    archive_existing_versions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1692392433395, current_stage='Production', description=('Moved version 4 is selected for production for this '\n",
       " 'chicago-taxi-prediction-model at 2023-08-18 17:02:11'), last_updated_timestamp=1692392531600, name='chicago-taxi-prediction-model', run_id='a6203da436864c7ea7d2ce768f2ec697', run_link='', source='s3://mlflow-artifact-remote-chicago-taxi-prediction/1/a6203da436864c7ea7d2ce768f2ec697/artifacts/models', status='READY', status_message='', tags={}, user_id='', version='4'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "client.update_model_version(\n",
    "    name=model_name,\n",
    "    version=4,\n",
    "    description=f\"Moved version 4 is selected for production for this {model_name} at {date}\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2022_mlzoomcamp-ubuntu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
