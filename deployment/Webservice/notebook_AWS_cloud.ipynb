{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import mlflow\n",
    "import pickle\n",
    "from hyperopt import hp, STATUS_OK, Trials, pyll,fmin,tpe\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket Name: mlflow-artifact-remote-chicago-taxi-prediction\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# List all buckets in your S3 account\n",
    "response = s3.list_buckets()\n",
    "buckets = response['Buckets']\n",
    "\n",
    "for bucket in buckets:\n",
    "    print(f\"Bucket Name: {bucket['Name']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACKING_SERVER_HOST = 'ec2-3-145-52-96.us-east-2.compute.amazonaws.com'\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking uri \"http://ec2-3-145-52-96.us-east-2.compute.amazonaws.com:5000\"\n"
     ]
    }
   ],
   "source": [
    "print(f'tracking uri \"{mlflow.get_tracking_uri()}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://mlflow-artifact-remote-chicago-taxi-prediction/1', creation_time=1691888942267, experiment_id='1', last_update_time=1691888942267, lifecycle_stage='active', name='chicago-taxi-experiment', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow_experiment_name = \"chicago-taxi-experiment\"\n",
    "\n",
    "mlflow.set_experiment(mlflow_experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN DATASET:\n",
    "Train_parquet_file_path = 'data/chicago_taxi_train_dataset_2023-01.parquet'  # Replace with the desired Parquet file path\n",
    "# VALIDATION DATASET:\n",
    "Val_parquet_file_path = 'data/chicago_taxi_Val_dataset_2023-02.parquet'\n",
    "# TEST DATASET:\n",
    "Test_parquet_file_path = 'data/chicago_taxi_test_dataset_2023-03.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_r = pd.read_parquet(Train_parquet_file_path)\n",
    "df_val_r = pd.read_parquet(Val_parquet_file_path)\n",
    "df_test_r = pd.read_parquet(Test_parquet_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 414478 entries, 0 to 414477\n",
      "Data columns (total 23 columns):\n",
      " #   Column                      Non-Null Count   Dtype         \n",
      "---  ------                      --------------   -----         \n",
      " 0   trip_id                     414478 non-null  object        \n",
      " 1   taxi_id                     414457 non-null  object        \n",
      " 2   trip_start_timestamp        414478 non-null  datetime64[ns]\n",
      " 3   trip_end_timestamp          414461 non-null  datetime64[ns]\n",
      " 4   trip_seconds                414378 non-null  float64       \n",
      " 5   trip_miles                  414478 non-null  float64       \n",
      " 6   pickup_census_tract         136206 non-null  float64       \n",
      " 7   dropoff_census_tract        135485 non-null  float64       \n",
      " 8   pickup_community_area       414478 non-null  object        \n",
      " 9   dropoff_community_area      414478 non-null  object        \n",
      " 10  fare                        414073 non-null  float64       \n",
      " 11  tips                        414073 non-null  float64       \n",
      " 12  tolls                       414073 non-null  float64       \n",
      " 13  extras                      414073 non-null  float64       \n",
      " 14  trip_total                  414073 non-null  float64       \n",
      " 15  payment_type                414478 non-null  object        \n",
      " 16  company                     414478 non-null  object        \n",
      " 17  pickup_centroid_latitude    388885 non-null  float64       \n",
      " 18  pickup_centroid_longitude   388885 non-null  float64       \n",
      " 19  pickup_centroid_location    388885 non-null  object        \n",
      " 20  dropoff_centroid_latitude   376020 non-null  float64       \n",
      " 21  dropoff_centroid_longitude  376020 non-null  float64       \n",
      " 22  dropoff_centroid__location  376020 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(13), object(8)\n",
      "memory usage: 72.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train_r.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame, categorical_features: List[str], numerical_features: List[str], verbose: bool = False):\n",
    "\n",
    "    df = df[df.trip_seconds.notnull()]\n",
    "    df = df[df.trip_start_timestamp.notnull()]\n",
    "    \n",
    "    df = df[(df['trip_seconds'] > 60) & (df['trip_seconds'] < 3600)]\n",
    "\n",
    "    # Create the 'duration' column in minutes as the target variable\n",
    "    df['duration'] = df['trip_seconds'] / 60\n",
    "\n",
    "    # Preprocess categorical features\n",
    "    for column in categorical_features:\n",
    "        df[column].fillna(-1, inplace=True)\n",
    "        df[column] = df[column].astype('str')\n",
    "        df[column] = df[column].str.lower().str.replace(' ', '_')\n",
    "\n",
    "    # Select only the relevant columns\n",
    "    target = ['duration']\n",
    "    selected_columns = categorical_features + numerical_features + target\n",
    "    df = df[selected_columns]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nshape of the data: {df.shape}\")\n",
    "        print(f\"\\ndata types:\\n{df.dtypes}\")\n",
    "        print(f\"\\ncategorical_features: {categorical_features}\")\n",
    "        print(f\"\\nnumerical_features: {numerical_features}\")\n",
    "        print(f\"\\ntarget variable: {target}\")\n",
    "\n",
    "    return df[categorical_features + numerical_features], df[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "shape of the data: (542815, 3)\n",
      "\n",
      "data types:\n",
      "pickup_community_area      object\n",
      "dropoff_community_area     object\n",
      "duration                  float64\n",
      "dtype: object\n",
      "\n",
      "categorical_features: ['pickup_community_area', 'dropoff_community_area']\n",
      "\n",
      "numerical_features: []\n",
      "\n",
      "target variable: ['duration']\n"
     ]
    }
   ],
   "source": [
    "df_test, y_test = preprocess_data(\n",
    "    df_test_r,\n",
    "    categorical_features=['pickup_community_area','dropoff_community_area'],\n",
    "    numerical_features=[],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "shape of the data: (417382, 3)\n",
      "\n",
      "data types:\n",
      "pickup_community_area      object\n",
      "dropoff_community_area     object\n",
      "duration                  float64\n",
      "dtype: object\n",
      "\n",
      "categorical_features: ['pickup_community_area', 'dropoff_community_area']\n",
      "\n",
      "numerical_features: []\n",
      "\n",
      "target variable: ['duration']\n"
     ]
    }
   ],
   "source": [
    "df_val, y_val = preprocess_data(\n",
    "    df_val_r,\n",
    "    categorical_features=['pickup_community_area','dropoff_community_area'],\n",
    "    numerical_features=[],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "shape of the data: (387579, 3)\n",
      "\n",
      "data types:\n",
      "pickup_community_area      object\n",
      "dropoff_community_area     object\n",
      "duration                  float64\n",
      "dtype: object\n",
      "\n",
      "categorical_features: ['pickup_community_area', 'dropoff_community_area']\n",
      "\n",
      "numerical_features: []\n",
      "\n",
      "target variable: ['duration']\n"
     ]
    }
   ],
   "source": [
    "df_train, y_train = preprocess_data(\n",
    "    df_train_r,\n",
    "    categorical_features=['pickup_community_area','dropoff_community_area'],\n",
    "    numerical_features=[],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dictionaries(df:pd.DataFrame, categorical_features:List[str], numerical_features:List[str]):\n",
    "    dicts = df[categorical_features + numerical_features].to_dict(orient='records')\n",
    "    return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = prepare_dictionaries(\n",
    "    df_train,\n",
    "    categorical_features=['pickup_community_area','dropoff_community_area'],\n",
    "    numerical_features=[]\n",
    ")\n",
    "val_dict = prepare_dictionaries(\n",
    "    df_val,\n",
    "    categorical_features=['pickup_community_area','dropoff_community_area'],\n",
    "    numerical_features=[]\n",
    ")\n",
    "test_dict = prepare_dictionaries(\n",
    "    df_test,\n",
    "    categorical_features=['pickup_community_area','dropoff_community_area'],\n",
    "    numerical_features=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values\n",
    "y_val = y_val.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dv = DictVectorizer()\n",
    "# X_train = dv.fit_transform(train_dict)\n",
    "# X_val = dv.transform(val_dict)\n",
    "# X_test = dv.transform(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arundac23/enter/envs/mlops-project-2023/lib/python3.9/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/home/arundac23/enter/envs/mlops-project-2023/lib/python3.9/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/arundac23/enter/envs/mlops-project-2023/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 4}\n",
      "Validation RMSE: 8.11854983176106\n",
      "Test RMSE: 8.658390359289022\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "with mlflow.start_run(run_name='Random_forest'):\n",
    "    params = {\n",
    "        'n_estimators': 100, \n",
    "        'max_depth': 10, \n",
    "        'min_samples_split': 10,\n",
    "        'min_samples_leaf': 4\n",
    "    }\n",
    "\n",
    "    pipeline = make_pipeline(\n",
    "        DictVectorizer(),\n",
    "        RandomForestRegressor(random_state=42)\n",
    "    )\n",
    "\n",
    "    pipeline.fit(train_dict, y_train)\n",
    "    y_pred = pipeline.predict(val_dict)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    rmse_test = mean_squared_error(y_test, pipeline.predict(test_dict), squared=False)\n",
    "    mlflow.set_tag('developer', 'Arun Dhanapalan')\n",
    "    mlflow.set_tag('project', 'chicago-taxi-prediction')\n",
    "    mlflow.log_param('train-data_path', Train_parquet_file_path)\n",
    "    mlflow.log_param('Validation-data_path', Val_parquet_file_path)\n",
    "    mlflow.log_metric('val_rmse', rmse)\n",
    "    mlflow.log_metric('test_rmse', rmse_test)\n",
    "    mlflow.set_tag(\"model_name\", 'Random_forest')\n",
    "    mlflow.sklearn.log_model(pipeline, artifact_path=\"models\")\n",
    "    print(f'Hyperparameters: {params}')\n",
    "    print(f'Validation RMSE: {rmse}') \n",
    "    print(f'Test RMSE: {rmse_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "import mlflow\n",
    "\n",
    "ML_FLOW_TRACKING_URI = \"http://ec2-3-145-52-96.us-east-2.compute.amazonaws.com:5000\"\n",
    "client = MlflowClient(tracking_uri=ML_FLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.entities import ViewType\n",
    "runs = client.search_runs(\n",
    "    experiment_ids='1',\n",
    "    filter_string='metrics.test_rmse < 9',\n",
    "    run_view_type=ViewType.ACTIVE_ONLY\n",
    "    # max_results=5,\n",
    "    # order_by=[\"metrics.test_rmse ASC\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: a6203da436864c7ea7d2ce768f2ec697, \n",
      "Val_rmse: 8.119 \n",
      "Test rmse: 8.658\n",
      "run id: 5c5419efd6f64a9bb9f168860160a8dd, \n",
      "Val_rmse: 8.106 \n",
      "Test rmse: 8.645\n",
      "run id: 15c1ae822734476d96e118a9e7e7034a, \n",
      "Val_rmse: 8.127 \n",
      "Test rmse: 8.666\n",
      "run id: e5467e29da6f46a9ac9731515a9fa195, \n",
      "Val_rmse: 8.119 \n",
      "Test rmse: 8.658\n"
     ]
    }
   ],
   "source": [
    "for run in runs:\n",
    "    print(f\"run id: {run.info.run_id}, \\nVal_rmse: {run.data.metrics['val_rmse']:.3f} \\nTest rmse: {run.data.metrics['test_rmse']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(ML_FLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'chicago-taxi-prediction-model' already exists. Creating a new version of this model...\n",
      "2023/08/18 17:00:33 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: chicago-taxi-prediction-model, version 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs:/a6203da436864c7ea7d2ce768f2ec697/models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '4' of model 'chicago-taxi-prediction-model'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1692392433395, current_stage='None', description='', last_updated_timestamp=1692392433395, name='chicago-taxi-prediction-model', run_id='a6203da436864c7ea7d2ce768f2ec697', run_link='', source='s3://mlflow-artifact-remote-chicago-taxi-prediction/1/a6203da436864c7ea7d2ce768f2ec697/artifacts/models', status='READY', status_message='', tags={}, user_id='', version='4'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = \"a6203da436864c7ea7d2ce768f2ec697\"\n",
    "model_uri = f\"runs:/{run_id}/models\"\n",
    "print(model_uri)\n",
    "mlflow.register_model(model_uri=model_uri, name=\"chicago-taxi-prediction-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: 1, status: Staging\n",
      "version: 3, status: None\n",
      "version: 4, status: Production\n"
     ]
    }
   ],
   "source": [
    "model_name = 'chicago-taxi-prediction-model'\n",
    "latest_version = client.get_latest_versions(name=model_name)\n",
    "for version in latest_version:\n",
    "    print(f\"version: {version.version}, status: {version.current_stage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1692392433395, current_stage='Production', description='', last_updated_timestamp=1692392470411, name='chicago-taxi-prediction-model', run_id='a6203da436864c7ea7d2ce768f2ec697', run_link='', source='s3://mlflow-artifact-remote-chicago-taxi-prediction/1/a6203da436864c7ea7d2ce768f2ec697/artifacts/models', status='READY', status_message='', tags={}, user_id='', version='4'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=4,\n",
    "    stage=\"production\",\n",
    "    archive_existing_versions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1692392433395, current_stage='Production', description=('Moved version 4 is selected for production for this '\n",
       " 'chicago-taxi-prediction-model at 2023-08-18 17:02:11'), last_updated_timestamp=1692392531600, name='chicago-taxi-prediction-model', run_id='a6203da436864c7ea7d2ce768f2ec697', run_link='', source='s3://mlflow-artifact-remote-chicago-taxi-prediction/1/a6203da436864c7ea7d2ce768f2ec697/artifacts/models', status='READY', status_message='', tags={}, user_id='', version='4'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "client.update_model_version(\n",
    "    name=model_name,\n",
    "    version=4,\n",
    "    description=f\"Moved version 4 is selected for production for this {model_name} at {date}\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2022_mlzoomcamp-ubuntu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
